{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project: Breakthrough Game\n",
    "\n",
    "**Release Date:** 9 September 2022\n",
    "\n",
    "**Due Date:** 23:59, 15 October 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "**Breakthrough** was the winner of the 2001 8 × 8 Game Design Competition, sponsored by *About.com* and *Abstract Games Magazine*. When Dan Troyka formulated it, it was originally for a 7×7 board. We’re going to play it on a 6×6 board to limit the complexity. In terms of our terminology for the agent environment, Breakthrough is a fully observable, strategic, deterministic game. The game always results in a win for one of the two players. So what are you going to do? You are going to play the game of Breakthrough – not as yourself but through the surrogate of your program.\n",
    "\n",
    "How exactly do you code an AI to play this game? Well, like everything else in this course, we code an agent. An agent takes sensory input and reasons about it, and then outputs an action at each time step. You thus need to create a program that can read in a representation of the board (that’s the input) and output a legal move in Breakthrough. You then need a evaluation function to evaluate how good a board is to your agent. The better your evaluation function, the better your agent will be at picking good moves. You need to put some thought into the structure of your evaluation function.\n",
    "\n",
    "Aside from the evaluation function, you also need to decide a strategy for exploring the search space. Certainly you can use minimax search but you may want to decide whether you want to use alpha-beta pruning on top of this. You would want to make the best move that you can given the limited time for each move (further provided clarification below).\n",
    "\n",
    "**Required Files**:\n",
    "* template.py: contains code for playing breakthrough between two different game playing agents. Your minimax algorithm will be written in this file.\n",
    "* utils.py: contains some utility functions that can be used directly.\n",
    "\n",
    "**Honour Code**: Note that plagiarism will not be condoned! You may discuss with your classmates and check the internet for references, but you MUST NOT submit code/report that is copied directly from other sources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakthrough Technical Description\n",
    "\n",
    "<pre>\n",
    "<p style=\"text-align: center;\">\n",
    "<img src = 'imgs/breakthrough_board.png'>\n",
    "Figure 1. Game Board\n",
    "</p>\n",
    "</pre>\n",
    "Figure 1 shows our typical game board. Black (**B**) wins by moving one piece to the opposite side, row index 5. White (**W**) wins by moving one piece to row index 0. Kindly **follow the same indexing as provided in *Figure 1*, and write code only for moving Black**. A simple board inversion will make black’s code work seamlessly for white as well. This technique has been used in the game playing framework of *template.py* for managing this two player game (the `invert_board` function is provided in *util.py*).\n",
    "\n",
    "<pre>\n",
    "<p style=\"text-align: center;\">\n",
    "<img src = 'imgs/game_move.png'>\n",
    "Figure 2. Possible Moves\n",
    "</p>\n",
    "</pre>\n",
    "\n",
    "Pieces move one space directly forward or diagonally forward, and only capture diagonally forward. The possible moves have been illustrated in *Figure 2*. In this figure, the black pawn at (3, 2) can go to any of the three spaces indicated forward. The black pawn at (0,4) can either choose to move by going diagonally right or capture by going diagonally left. It cannot move or capture by moving forward; its forward move is blocked by the white pawn. Note that your move is not allowed to take your pawn outside the board.\n",
    "\n",
    "Your program will always play **black**, whose objective is to move a black pawn to row index 5. Given a move request, your agent should output a pair of coordinates in the form of a pair of one dimensional lists using the coordinate system shown in the figure. For example, for moving the black pawn standing at (0,4) in *Figure 2* to (1,3), your agent should make a move that returns the two lists: [0, 4] and [1, 3].\n",
    "\n",
    "Your agent should always provide a legal move. Moves will be validated by the game playing framework provided in *template.py*. Any illegal moves will result in a decrease in the score of your assignment. If your player makes an illegal move, the competition framework will choose the next available valid move on your behalf. Your agent must always make a move; it is not allowed to skip moves. Your program *cannot take more than 3 real-time seconds* to make a move. If your program does not output a coordinate within 3 seconds, it will decrease your assignment score further and the competition framework will choose a random move on your behalf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provided Utility Functions\n",
    "\n",
    "You can use the functions provided in *util.py* file as you see fit. These functions have mainly been used by the game playing framework in *template.py* to facilitate the two player game. A short description of these functions is given below:\n",
    "\n",
    "- `generate_init_state()`: It generates initial state (*Game Board in Figure 1*) at the start of the game.\n",
    "- `print_state(board)`: It takes in the board 2D list as parameter and prints out the current state of the board in a convenient way (sample shown in *Possible Moves in Figure 2*).\n",
    "- `is_game_over(board)`: Given a board configuration, it returns `True` if the game is over, `False` otherwise.\n",
    "- `is_valid_move(board, src, dst)`: It takes in the board configuration and the move source and move destination as its parameters. It returns `True` if the move is valid and returns `False` if the move is invalid.\n",
    "- `state_change(board, src, dst)`: Given a board configuration and a move source and move destination, this function changes board configuration in accordance to the indicated move.\n",
    "- generate_rand_move(board): It takes in the board configuration as its parameter and generates an arbitrary valid move in the form of two lists. You likely won’t need to use this function. This function is used by the game playing framework in one of two cases - (1) an invalid move has been made by the game playing agent or, (2) the game playing agent has taken more than 3 seconds to make its move.\n",
    "- `invert_board(board)`: It takes in the board 2D list as parameter and returns the inverted board. You should always code for black, not for white. The game playing agent in *main.py* has to make move for both black and white using only black’s code. So, when it is time for white to make its move, we invert the board using this function to see everything from white side’s perspective (done by inverting the colors of each pawn and by modifying the row indices). An example of inversion has been shown in *Figure 3 Board Inversion Illustration* later. In your minimax algorithm, you need to consider both black and white alternatively. Instead of writing the same code twice separately for black and white, you can use `invert_board()` function to invert your board configuration that enables you to utilize black’s codes for white pawns as well. That is enough for hints, I guess.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Your Game Playing Agent\n",
    "\n",
    "Fill in `make_move(board)` method of the `PlayerAI` class with your game playing agent code (you can write as many assisting function as you deem fit). The `PlayerNaive` class has been provided for you to test out your agent against another program. Always code for Black (assume Black as max player) in both these class functions. The game playing framework calls the `make_move(board)` method of each agent alternatively. After you complete `PlayerAI`, simply run the *template.py* file. You will see the two agents (`PlayerAI` and `PlayerNaive`) playing against each other.\n",
    "\n",
    "**Always remember to return your move within 3 seconds.** You should check for time passed during every recursive call in minimax algorithm to follow this 3 second rule. Whenever you see that 3 seconds is almost over, immediately return the best move you have at your disposal. That is all the hint I can give you. This is really important because the machine where we will run your code maybe much slower than your local machine.\n",
    "\n",
    "<pre>\n",
    "<p style=\"text-align: center;\">\n",
    "<img src = 'imgs/invert_board.png'>\n",
    "Figure 3. Board Inversion Illustration\n",
    "</p>\n",
    "</pre>\n",
    "\n",
    "You have chance to be innovative mainly in 3 areas - (1) the evaluation function used to evaluate the goodness of a state, (2) effective exploration strategy maintaining the time constraint and (3) modifying the alpha beta pruning algorithm for more efficient search. Ultimately, we shall be playing all the student designed agents against each other. So, it will be a small breakthrough tournament. The top players will get some bonus marks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Guidelines\n",
    "\n",
    "This mini-project will constitute 10% of your overall grade for CS2109S. The following is the criteria under which your submission will be graded.\n",
    "\n",
    "Your code will constitute 60% of this mini-project grade. We look for:\n",
    "- **Making Valid Moves (5%)**: Ensure your moves are valid and complete every move within 3 seconds to get full marks for this section.\n",
    "- **Performance Against Baseline Agent (15%)**: Your submitted agent code will be run against our baby agent and a base agent. You should win all our agents and make less than or equal to 3 random moves to get the full credit for this section.\n",
    "- **Algorithm Implementation Check (30%)**: If you implement the minimax algorithms and the alpha beta correctly, you receive these marks irrespective of the performance of your agent.\n",
    "- **Evaluation Function Check (10%)**: Remember this is a zero-sum game, so your evaluation function should maximize your probability of winning while minimize other player's chance of winning.\n",
    "\n",
    "Your report will constitute 40% of this mini-project grade. We look for:\n",
    "- **Data Structure Description (5%)**: Describe your data structure and how it describes the game state fully. Specify explicitly how the initial state, and some goal state is represented using your data structure.\n",
    "- **Evaluation Function Description (10%)**: Explain how your evaluation function works too!\n",
    "- **Novel solution (25%)**: This is the part where we give even more credits to your well-designed submissions. To give some examples, in the novel solution section we look for:\n",
    "<ol style=\"list-style-type: lower-alpha\">\n",
    "<li>any good data structures that increase the efficiency. Think about how slow and memory consuming it is to use 2D list of strings to represent the board, not to mention we need to keep flipping. Come up with good data structures to possibly speed up board access and score computation. Some examples of good structure are hash table with well-defined hashing method, bit representation of game state etc.</li>\n",
    "<li>any good ways of performing search space exploration. Remember we have time limit for each move, and it's not possible to look at all future states before making a decision. Could you think of a better way to search to get the best possible move within the time limit? Could you think of ways to improve your pruning, by possibly adopting a good order of pruning?</li>\n",
    "<li>any good evaluation functions. You are encouraged to play the game yourself, and/or read some research papers to know the game better and discover any good strategies that can help you improve your evaluation function. Some possible directions you can consider are considering the neighborhood and prioritizing some pieces, and putting different weights on several heuristics.</li>\n",
    "</ol>\n",
    "Note that none of the list above is exhaustive. Feel free to come up with other creative ways to improve your program. You are also encouraged to read research papers and implement some of the algorithms.\n",
    "\n",
    "Try your best and enjoy!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Make sure to import utils.py provided before proceeding\n",
    "\"\"\"\n",
    "\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Valid Move Given a Board Representation\n",
    "\n",
    "Input: A board state represented as a 2D list\n",
    "\n",
    "Output: two 1D lists representing source and destination of your move\n",
    "\n",
    "Note: Your move has to be valid and it has to be made within 3 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import copy\n",
    "from queue import PriorityQueue\n",
    "import utils\n",
    "\n",
    "class PlayerAI:\n",
    "    def __init__(self):\n",
    "        self.score_table = {}\n",
    "        self.breaked = False\n",
    "\n",
    "    # Represent a board as a string for hashing purposes\n",
    "    def stringify_board(self, board):\n",
    "        return ''.join(''.join(row) for row in board)\n",
    "\n",
    "    # Evaluate the board state from the perspective of the black player\n",
    "    def evaluate_board(self, board, is_black):\n",
    "        evaluating_board = board if is_black else self.invert_board(board)\n",
    "        board_repr = self.stringify_board(evaluating_board)\n",
    "\n",
    "        if board_repr in self.score_table:\n",
    "            return self.score_table[board_repr]\n",
    "\n",
    "        # Check for winning/losing states\n",
    "        for i in range(6):\n",
    "            if evaluating_board[0][i] == 'W':\n",
    "                return -1000\n",
    "            if evaluating_board[5][i] == 'B':\n",
    "                return 1000\n",
    "\n",
    "        final_score = 0\n",
    "        offensive_score = 0\n",
    "        defensive_score = 6\n",
    "\n",
    "        piece_score = 10\n",
    "        position_score = 10\n",
    "        danger_penalty = 30\n",
    "        protected_bonus = 55\n",
    "        empty_column_penalty = 20\n",
    "\n",
    "        for j in range(6):\n",
    "            has_black = False\n",
    "            has_white = False\n",
    "\n",
    "            for i in range(6):\n",
    "                cell = evaluating_board[i][j]\n",
    "                if cell == \"B\":\n",
    "                    has_black = True\n",
    "                    offensive_score = max(offensive_score, i)\n",
    "                    final_score += piece_score + i * position_score\n",
    "\n",
    "                    if self.is_endangered(evaluating_board, i, j):\n",
    "                        final_score -= danger_penalty\n",
    "                        if self.is_protected(evaluating_board, i, j):\n",
    "                            final_score += protected_bonus\n",
    "\n",
    "                elif cell == \"W\":\n",
    "                    has_white = True\n",
    "                    if i == 1:\n",
    "                        final_score -= 100\n",
    "                    defensive_score = min(defensive_score, i)\n",
    "                    final_score -= piece_score + (5 - i) * position_score\n",
    "\n",
    "            if not has_black:\n",
    "                final_score -= empty_column_penalty\n",
    "                if has_white:\n",
    "                    final_score -= empty_column_penalty\n",
    "\n",
    "        final_score += 30 * defensive_score + 5 * offensive_score\n",
    "        self.score_table[board_repr] = final_score\n",
    "        return final_score\n",
    "\n",
    "    def is_endangered(self, board, i, j):\n",
    "        for pos in [(i + 1, j + 1), (i + 1, j - 1)]:\n",
    "            if self.is_within_bounds(*pos) and board[pos[0]][pos[1]] == \"W\":\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def is_protected(self, board, i, j):\n",
    "        for pos in [(i - 1, j + 1), (i - 1, j - 1)]:\n",
    "            if self.is_within_bounds(*pos) and board[pos[0]][pos[1]] == \"B\":\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def is_within_bounds(self, x, y):\n",
    "        return 0 <= x < 6 and 0 <= y < 6\n",
    "\n",
    "    def invert_board(self, board):\n",
    "        inverted_board = copy.deepcopy(board)\n",
    "        utils.invert_board(inverted_board)\n",
    "        return inverted_board\n",
    "\n",
    "    # Generate all possible moves for the player\n",
    "    def possible_moves(self, board, is_black):\n",
    "        moves = PriorityQueue()\n",
    "        starting_positions = [(i, j) for i in range(6) for j in range(6) if board[i][j] == 'B']\n",
    "\n",
    "        for x_cord, y_cord in starting_positions:\n",
    "            for x_move, y_move in [(1, 0), (1, -1), (1, 1)]:\n",
    "                new_move = [[x_cord, y_cord], [x_cord + x_move, y_cord + y_move]]\n",
    "                if utils.is_valid_move(board, new_move[0], new_move[1]):\n",
    "                    temp_board = copy.deepcopy(board)\n",
    "                    utils.state_change(temp_board, new_move[0], new_move[1])\n",
    "                    score = self.evaluate_board(temp_board, is_black)\n",
    "                    moves.put((-score if is_black else score, new_move))\n",
    "\n",
    "        return moves\n",
    "\n",
    "    def make_move(self, board):\n",
    "        start_time = time.time()\n",
    "        end_time = start_time + 2.9\n",
    "        depth = 1\n",
    "        current_best_move = None\n",
    "\n",
    "        while time.time() < end_time:\n",
    "            self.breaked = False\n",
    "            current_search = self.minimax(board, depth, True, -math.inf, math.inf, end_time)\n",
    "\n",
    "            if self.breaked:\n",
    "                break\n",
    "\n",
    "            _, current_best_move = current_search\n",
    "            depth += 1\n",
    "\n",
    "        return current_best_move\n",
    "\n",
    "    def minimax(self, board, depth, is_black, alpha, beta, end_time):\n",
    "        if utils.is_game_over(board) or depth == 0:\n",
    "            return self.evaluate_board(board, is_black), None\n",
    "\n",
    "        best_move = None\n",
    "\n",
    "        if is_black:\n",
    "            best_score = -math.inf\n",
    "            moves = self.possible_moves(board, True)\n",
    "            while not moves.empty():\n",
    "                if time.time() > end_time:\n",
    "                    self.breaked = True\n",
    "                    break\n",
    "\n",
    "                current_move = moves.get()[1]\n",
    "                new_board = self.invert_board_after_move(board, current_move)\n",
    "                current_score, _ = self.minimax(new_board, depth - 1, False, alpha, beta, end_time)\n",
    "                if current_score > best_score:\n",
    "                    best_score = current_score\n",
    "                    best_move = current_move\n",
    "                alpha = max(alpha, best_score)\n",
    "                if alpha >= beta:\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            best_score = math.inf\n",
    "            moves = self.possible_moves(board, False)\n",
    "            while not moves.empty():\n",
    "                if time.time() > end_time:\n",
    "                    self.breaked = True\n",
    "                    break\n",
    "\n",
    "                current_move = moves.get()[1]\n",
    "                new_board = self.invert_board_after_move(board, current_move)\n",
    "                current_score, _ = self.minimax(new_board, depth - 1, True, alpha, beta, end_time)\n",
    "                if current_score < best_score:\n",
    "                    best_score = current_score\n",
    "                    best_move = current_move\n",
    "                beta = min(beta, best_score)\n",
    "                if alpha >= beta:\n",
    "                    break\n",
    "\n",
    "        return best_score, best_move\n",
    "\n",
    "    def invert_board_after_move(self, board, move):\n",
    "        new_board = copy.deepcopy(board)\n",
    "        utils.state_change(new_board, move[0], move[1])\n",
    "        utils.invert_board(new_board)\n",
    "        return new_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayerNaive:\n",
    "    ''' A naive agent that will always return the first available valid move '''\n",
    "    def make_move(self, board):\n",
    "        return utils.generate_rand_move(board)\n",
    "\n",
    "# You may replace PLAYERS with any two players of your choice\n",
    "PLAYERS = [PlayerAI(), PlayerNaive()]\n",
    "COLOURS = [BLACK, WHITE] = 'Black', 'White'\n",
    "TIMEOUT = 3.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|  B  |  B  |  B  |  B  |  B  |  B  |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|  B  |  B  |  B  |  B  |  B  |  B  |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|     |     |     |     |     |     |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|     |     |     |     |     |     |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|  W  |  W  |  W  |  W  |  W  |  W  |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|  W  |  W  |  W  |  W  |  W  |  W  |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "Move No: 0 by Black\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|  B  |  B  |  B  |  B  |  B  |  B  |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|     |  B  |  B  |  B  |  B  |  B  |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|  B  |     |     |     |     |     |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|     |     |     |     |     |     |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|  W  |  W  |  W  |  W  |  W  |  W  |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|  W  |  W  |  W  |  W  |  W  |  W  |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "Move No: 1 by White\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|  B  |  B  |  B  |  B  |  B  |  B  |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|     |  B  |  B  |  B  |  B  |  B  |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|  B  |     |     |     |     |     |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|  W  |     |     |     |     |     |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|     |  W  |  W  |  W  |  W  |  W  |\n",
      "+-----+-----+-----+-----+-----+-----+\n",
      "|  W  |  W  |  W  |  W  |  W  |  W  |\n",
      "+-----+-----+-----+-----+-----+-----+\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "# Game playing framework #\n",
    "##########################\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    print(\"Initial State\")\n",
    "    board = utils.generate_init_state()\n",
    "    utils.print_state(board)\n",
    "    move = 0\n",
    "\n",
    "    # game starts\n",
    "    while not utils.is_game_over(board):\n",
    "        player = PLAYERS[move % 2]\n",
    "        colour = COLOURS[move % 2]\n",
    "        if colour == WHITE: # invert if white\n",
    "            utils.invert_board(board)\n",
    "        start = time.time()\n",
    "        src, dst = player.make_move(board) # returns [i1, j1], [i2, j2] -> pawn moves from position [i1, j1] to [i2, j2]\n",
    "        end = time.time()\n",
    "        within_time = end - start <= TIMEOUT\n",
    "        valid = utils.is_valid_move(board, src, dst) # checks if move is valid\n",
    "        if not valid or not within_time: # if move is invalid or time is exceeded, then we give a random move\n",
    "            print('executing random move')\n",
    "            src, dst = utils.generate_rand_move(board)\n",
    "        utils.state_change(board, src, dst) # makes the move effective on the board\n",
    "        if colour == WHITE: # invert back if white\n",
    "            utils.invert_board(board)\n",
    "\n",
    "        print(f'Move No: {move} by {colour}')\n",
    "        utils.print_state(board) # printing the current configuration of the board after making move\n",
    "        move += 1\n",
    "    print(f'{colour} Won')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
